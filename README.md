# RL and Advanced DL at MADE, 2021

Это курс об обучении с подкреплением и порождающих моделях в глубоком обучении, представленный в [Академии больших данных Mail.Ru](https://data.mail.ru/) в 2021 году. <!--- [Все материалы](https://logic.pdmi.ras.ru/~sergey/teaching/maderl2021.html)-->

# Лекции
1. Введение в обучение с подкреплением. Многорукие бандиты  <!--- :[запись](https://www.youtube.com/watch?v=xW1dxZNeWWk)-->
2. Конкурентные и контекстуальные бандиты. Обучение с подкреплением: определение MDP, уравнения Беллмана. Сложности в решении уравнений Беллмана. Policy iteration  <!--- :[запись](https://www.youtube.com/watch?v=sVehB6JgWIs)-->
3. Обучение стратегий без модели: методы Монте-Карло, от MC estimation к MC control. On-policy и off-policy методы. TD-обучение: Sarsa (on-policy TD-обучение) и Q-learning (off-policy TD-обучение) <!--- :[запись](https://youtu.be/4chjddQ3UVk)-->
4. Обобщения TD и MC-методов: n-step RL и так далее. Планирование: rollouts, MCTS <!--- :[запись](https://youtu.be/ZHImFAYg0xk)-->
5. Приближённые методы в RL и градиент по стратегиям (policy gradient) <!--- :[запись](https://youtu.be/s1qzIlCNeVU)-->

# Домашние задания
1. Учимся обыгрывать казино: RL с блекджеком и Дастином Хоффманом.
2. Играем в крестики-нолики: Q-обучение, DQN, MCTS и (может быть) AlphaZero.

# Selected references
1. Richard S. Sutton, Andrew G. Barto.  Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 2018.
