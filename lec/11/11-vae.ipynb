{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snikolenko/soft/lectures/lectures/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## загружаем MNIST\n",
    "image_size = 28\n",
    "image_shape = (1, image_size, image_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "batch_size = 64\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"data/mnist\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) \n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/mnist\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader=dataloader, testloader=testloader, sample_dir=None, show_test_loss=False):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if sample_dir is not None:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(25, 2).cuda()\n",
    "            sample = vae.decoder(z).cuda()\n",
    "            save_image(sample.view(25, 1, 28, 28), \"%s/%02d.png\" % (sample_dir, epoch), nrow=5, normalize=True)\n",
    "    if show_test_loss:\n",
    "        vae.eval()\n",
    "        test_loss=0\n",
    "        with torch.no_grad():\n",
    "            for data, _ in testloader:\n",
    "                data = data.cuda()\n",
    "                recon, mu, log_var = vae(data)\n",
    "                test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        print('\\tepoch %2d\\ttrain set loss %.4f\\ttest set loss %.4f' % (epoch, train_loss / len(dataloader.dataset), test_loss / len(testloader.dataset)))\n",
    "    else:\n",
    "        print('\\tepoch %d\\taverage loss %.4f' % (epoch, train_loss / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch  1\ttrain set loss 174.8316\ttest set loss 159.1139\n",
      "\tepoch  2\ttrain set loss 155.3211\ttest set loss 153.4206\n",
      "\tepoch  3\ttrain set loss 150.5982\ttest set loss 149.1550\n",
      "\tepoch  4\ttrain set loss 147.9355\ttest set loss 147.7394\n",
      "\tepoch  5\ttrain set loss 145.8305\ttest set loss 146.3652\n",
      "\tepoch  6\ttrain set loss 144.8009\ttest set loss 145.1928\n",
      "\tepoch  7\ttrain set loss 143.6917\ttest set loss 144.0797\n",
      "\tepoch  8\ttrain set loss 142.8939\ttest set loss 143.3491\n",
      "\tepoch  9\ttrain set loss 142.2042\ttest set loss 143.0468\n",
      "\tepoch 10\ttrain set loss 141.6058\ttest set loss 142.4549\n",
      "\tepoch 11\ttrain set loss 141.0041\ttest set loss 141.6941\n",
      "\tepoch 12\ttrain set loss 140.5090\ttest set loss 141.3108\n",
      "\tepoch 13\ttrain set loss 140.1729\ttest set loss 141.6779\n",
      "\tepoch 14\ttrain set loss 139.7718\ttest set loss 141.1683\n",
      "\tepoch 15\ttrain set loss 139.3873\ttest set loss 140.2652\n",
      "\tepoch 16\ttrain set loss 139.0587\ttest set loss 140.6277\n",
      "\tepoch 17\ttrain set loss 138.8009\ttest set loss 140.1999\n",
      "\tepoch 18\ttrain set loss 138.5478\ttest set loss 140.6141\n",
      "\tepoch 19\ttrain set loss 138.4417\ttest set loss 140.0776\n",
      "\tepoch 20\ttrain set loss 138.2046\ttest set loss 140.4208\n",
      "\tepoch 21\ttrain set loss 138.0370\ttest set loss 139.9747\n",
      "\tepoch 22\ttrain set loss 137.6048\ttest set loss 139.0880\n",
      "\tepoch 23\ttrain set loss 137.6590\ttest set loss 139.4910\n",
      "\tepoch 24\ttrain set loss 137.4890\ttest set loss 139.1079\n",
      "\tepoch 25\ttrain set loss 137.1719\ttest set loss 139.1141\n",
      "\tepoch 26\ttrain set loss 137.2005\ttest set loss 138.8786\n",
      "\tepoch 27\ttrain set loss 136.9253\ttest set loss 139.1311\n",
      "\tepoch 28\ttrain set loss 136.9496\ttest set loss 138.7608\n",
      "\tepoch 29\ttrain set loss 136.5445\ttest set loss 139.1714\n",
      "\tepoch 30\ttrain set loss 136.4676\ttest set loss 138.8917\n",
      "\tepoch 31\ttrain set loss 136.4728\ttest set loss 138.4950\n",
      "\tepoch 32\ttrain set loss 136.5389\ttest set loss 138.4625\n",
      "\tepoch 33\ttrain set loss 136.1852\ttest set loss 138.9246\n",
      "\tepoch 34\ttrain set loss 136.1800\ttest set loss 139.5237\n",
      "\tepoch 35\ttrain set loss 135.9176\ttest set loss 138.2002\n",
      "\tepoch 36\ttrain set loss 135.9816\ttest set loss 138.6280\n",
      "\tepoch 37\ttrain set loss 135.8011\ttest set loss 138.1196\n",
      "\tepoch 38\ttrain set loss 135.6198\ttest set loss 138.0449\n",
      "\tepoch 39\ttrain set loss 135.5964\ttest set loss 138.3464\n",
      "\tepoch 40\ttrain set loss 135.6809\ttest set loss 138.2011\n",
      "\tepoch 41\ttrain set loss 135.3923\ttest set loss 138.2307\n",
      "\tepoch 42\ttrain set loss 135.1781\ttest set loss 138.0135\n",
      "\tepoch 43\ttrain set loss 135.0290\ttest set loss 138.1904\n",
      "\tepoch 44\ttrain set loss 135.3372\ttest set loss 137.9659\n",
      "\tepoch 45\ttrain set loss 135.0683\ttest set loss 138.5141\n",
      "\tepoch 46\ttrain set loss 135.2712\ttest set loss 138.1573\n",
      "\tepoch 47\ttrain set loss 134.9981\ttest set loss 138.3620\n",
      "\tepoch 48\ttrain set loss 134.8522\ttest set loss 138.8345\n",
      "\tepoch 49\ttrain set loss 135.0421\ttest set loss 138.6635\n",
      "\tepoch 50\ttrain set loss 134.9189\ttest set loss 137.7106\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch, sample_dir='data/images/vae', show_test_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Url](results_vae.gif \"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionloader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        \"data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "fashiontestloader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        \"data/mnist\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch  1\ttrain set loss 298.5994\ttest set loss 281.1881\n",
      "\tepoch  2\ttrain set loss 276.7529\ttest set loss 276.0567\n",
      "\tepoch  3\ttrain set loss 273.2074\ttest set loss 272.7264\n",
      "\tepoch  4\ttrain set loss 270.4568\ttest set loss 271.7459\n",
      "\tepoch  5\ttrain set loss 268.7618\ttest set loss 269.4839\n",
      "\tepoch  6\ttrain set loss 267.5545\ttest set loss 268.0630\n",
      "\tepoch  7\ttrain set loss 266.1332\ttest set loss 267.1256\n",
      "\tepoch  8\ttrain set loss 264.9262\ttest set loss 266.5327\n",
      "\tepoch  9\ttrain set loss 264.0914\ttest set loss 266.2383\n",
      "\tepoch 10\ttrain set loss 263.4620\ttest set loss 264.1531\n",
      "\tepoch 11\ttrain set loss 262.8270\ttest set loss 263.8486\n",
      "\tepoch 12\ttrain set loss 262.4700\ttest set loss 263.9861\n",
      "\tepoch 13\ttrain set loss 262.3701\ttest set loss 263.9473\n",
      "\tepoch 14\ttrain set loss 261.9632\ttest set loss 262.9336\n",
      "\tepoch 15\ttrain set loss 261.5779\ttest set loss 263.0345\n",
      "\tepoch 16\ttrain set loss 261.4053\ttest set loss 263.5711\n",
      "\tepoch 17\ttrain set loss 261.1775\ttest set loss 262.6611\n",
      "\tepoch 18\ttrain set loss 260.5781\ttest set loss 262.2780\n",
      "\tepoch 19\ttrain set loss 260.5715\ttest set loss 263.1689\n",
      "\tepoch 20\ttrain set loss 260.6982\ttest set loss 262.7539\n",
      "\tepoch 21\ttrain set loss 260.3119\ttest set loss 261.4758\n",
      "\tepoch 22\ttrain set loss 260.3876\ttest set loss 263.6359\n",
      "\tepoch 23\ttrain set loss 260.0798\ttest set loss 261.3396\n",
      "\tepoch 24\ttrain set loss 259.7402\ttest set loss 261.6807\n",
      "\tepoch 25\ttrain set loss 259.6858\ttest set loss 261.7608\n",
      "\tepoch 26\ttrain set loss 259.7410\ttest set loss 261.3042\n",
      "\tepoch 27\ttrain set loss 259.5830\ttest set loss 261.0211\n",
      "\tepoch 28\ttrain set loss 259.2721\ttest set loss 261.0244\n",
      "\tepoch 29\ttrain set loss 259.4925\ttest set loss 260.8986\n",
      "\tepoch 30\ttrain set loss 259.0527\ttest set loss 260.6923\n",
      "\tepoch 31\ttrain set loss 259.1148\ttest set loss 260.8905\n",
      "\tepoch 32\ttrain set loss 259.5126\ttest set loss 262.8739\n",
      "\tepoch 33\ttrain set loss 259.1508\ttest set loss 261.3285\n",
      "\tepoch 34\ttrain set loss 259.1264\ttest set loss 260.3899\n",
      "\tepoch 35\ttrain set loss 258.9351\ttest set loss 260.7890\n",
      "\tepoch 36\ttrain set loss 258.9843\ttest set loss 260.5587\n",
      "\tepoch 37\ttrain set loss 258.7929\ttest set loss 262.1544\n",
      "\tepoch 38\ttrain set loss 258.7640\ttest set loss 259.7012\n",
      "\tepoch 39\ttrain set loss 258.7344\ttest set loss 260.6480\n",
      "\tepoch 40\ttrain set loss 258.5375\ttest set loss 259.9277\n",
      "\tepoch 41\ttrain set loss 258.5648\ttest set loss 262.1993\n",
      "\tepoch 42\ttrain set loss 258.7956\ttest set loss 260.1022\n",
      "\tepoch 43\ttrain set loss 258.6924\ttest set loss 259.9800\n",
      "\tepoch 44\ttrain set loss 258.2872\ttest set loss 259.5363\n",
      "\tepoch 45\ttrain set loss 258.3078\ttest set loss 260.6573\n",
      "\tepoch 46\ttrain set loss 258.7113\ttest set loss 260.6070\n",
      "\tepoch 47\ttrain set loss 258.3366\ttest set loss 259.7859\n",
      "\tepoch 48\ttrain set loss 258.7500\ttest set loss 259.4639\n",
      "\tepoch 49\ttrain set loss 257.9938\ttest set loss 259.5513\n",
      "\tepoch 50\ttrain set loss 258.0608\ttest set loss 261.6673\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch, dataloader=fashionloader, testloader=fashiontestloader, sample_dir='data/images/vae_fashion', show_test_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Url](results_vae_fashion.gif \"VAE Fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
